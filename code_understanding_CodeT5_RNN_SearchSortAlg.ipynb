{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeT5-RNN using SearchSortAlg dataset\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5EncoderModel, AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Dataset class\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, codes, labels, tokenizer, max_length):\n",
    "        self.codes = codes\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.codes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code = self.codes[idx]\n",
    "        label = self.labels[idx]\n",
    "        if isinstance(code, list):\n",
    "            code = [str(i) for i in code]\n",
    "        else:\n",
    "            code = [str(code)]\n",
    "        encodings = self.tokenizer(code, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "        input_ids = encodings['input_ids'].squeeze()\n",
    "        attention_mask = encodings['attention_mask'].squeeze()\n",
    "        return input_ids, attention_mask, label\n",
    "\n",
    "# Model class\n",
    "class CodeClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes, hidden_dim):\n",
    "        super(CodeClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.gru = nn.LSTM(input_size=768, hidden_size=hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        gru_outputs, _ = self.gru(encoder_outputs)\n",
    "        pooled_output = torch.max(gru_outputs, 1)[0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Function to load and split the custom dataset\n",
    "def load_and_split_dataset(file_path, test_size=0.2, val_size=0.1):\n",
    "    df = pd.read_csv(file_path)\n",
    "    codes = df['Code'].tolist()\n",
    "    labels = df['Class'].tolist()\n",
    "\n",
    "    train_val_codes, test_codes, train_val_labels, test_labels = train_test_split(codes, labels, test_size=test_size, random_state=42)\n",
    "    train_codes, valid_codes, train_labels, valid_labels = train_test_split(train_val_codes, train_val_labels, test_size=val_size, random_state=42)\n",
    "\n",
    "    return (train_codes, train_labels), (valid_codes, valid_labels), (test_codes, test_labels)\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    return encoded_labels, encoder\n",
    "\n",
    "# Prepare DataLoader\n",
    "def create_dataloaders(train_data, valid_data, batch_size, tokenizer, max_length):\n",
    "    train_dataset = CodeDataset(train_data[0], train_data[1], tokenizer, max_length)\n",
    "    valid_dataset = CodeDataset(valid_data[0], valid_data[1], tokenizer, max_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs, learning_rate=2e-5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.NAdam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, labels in train_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for input_ids, attention_mask, labels in val_loader:\n",
    "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "        print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model and print metrics\n",
    "def evaluate_model(model, test_data, device, encoder, batch_size, tokenizer, max_length):\n",
    "    test_dataset = CodeDataset(test_data[0], test_data[1], tokenizer, max_length)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    total_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in test_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, test_preds)\n",
    "    precision = precision_score(test_labels, test_preds, average='weighted')\n",
    "    recall = recall_score(test_labels, test_preds, average='weighted')\n",
    "    f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        'loss': total_loss / len(test_loader),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(test_labels, test_preds, target_names=encoder.classes_)\n",
    "    print(\"Classification Report: \\n\", report)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Save the model\n",
    "def save_model(model, path='code_classifier.pth'):\n",
    "    create_directory_if_not_exists(path)\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Load the model\n",
    "def load_model(path, encoder, num_classes, hidden_dim):\n",
    "    model = CodeClassifier(encoder, num_classes, hidden_dim)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "# Ensure directory creation for saving models\n",
    "def create_directory_if_not_exists(path):\n",
    "    directory = os.path.dirname(path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and split the dataset\n",
    "    dataset_file = 'sort_search_row_converted_filtered.csv'\n",
    "    (train_codes, train_labels), (valid_codes, valid_labels), (test_codes, test_labels) = load_and_split_dataset(dataset_file)\n",
    "\n",
    "    # Encode labels\n",
    "    train_labels, label_encoder = encode_labels(train_labels)\n",
    "    valid_labels = label_encoder.transform(valid_labels)\n",
    "    test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "    # Load tokenizer and preprocess data\n",
    "    pretrained_model_name = \"Salesforce/codet5-base\"  # Replace with your pre-trained model name\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "    max_length = 512\n",
    "\n",
    "    # Prepare dataloaders\n",
    "    batch_size = 8\n",
    "    train_loader, val_loader = create_dataloaders((train_codes, train_labels), (valid_codes, valid_labels), batch_size, tokenizer, max_length)\n",
    "\n",
    "    # Load the encoder model\n",
    "    encoder_model = T5EncoderModel.from_pretrained(pretrained_model_name)\n",
    "\n",
    "    # Build and train the model\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    hidden_dim = 512\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CodeClassifier(encoder_model, num_classes, hidden_dim)\n",
    "\n",
    "    train_model(model, train_loader, val_loader, device, num_epochs=5)\n",
    "\n",
    "    # Save the trained model\n",
    "    save_model(model, 'model_saves/code_classifier.pth')\n",
    "\n",
    "    # Load the model for prediction\n",
    "    loaded_model = load_model('model_saves/code_classifier.pth', encoder_model, num_classes, hidden_dim)\n",
    "    loaded_model.to(device)\n",
    "\n",
    "    # Evaluate the model on training, validation, and test datasets\n",
    "    print(\"Train Dataset:\")\n",
    "    train_metrics = evaluate_model(loaded_model, (train_codes, train_labels), device, label_encoder, batch_size, tokenizer, max_length)\n",
    "\n",
    "    print(\"Validation Dataset:\")\n",
    "    val_metrics = evaluate_model(loaded_model, (valid_codes, valid_labels), device, label_encoder, batch_size, tokenizer, max_length)\n",
    "\n",
    "    print(\"Test Dataset:\")\n",
    "    test_metrics = evaluate_model(loaded_model, (test_codes, test_labels), device, label_encoder, batch_size, tokenizer, max_length)\n",
    "\n",
    "    # Print metrics in the desired format\n",
    "    print(\"\\neval_loss\\teval_accuracy\\teval_f1\\teval_precision\\teval_recall\")\n",
    "    print(f\"train\\t{train_metrics['loss']:.6f}\\t{train_metrics['accuracy']:.6f}\\t{train_metrics['f1']:.6f}\\t{train_metrics['precision']:.6f}\\t{train_metrics['recall']:.6f}\")\n",
    "    print(f\"val\\t{val_metrics['loss']:.6f}\\t{val_metrics['accuracy']:.6f}\\t{val_metrics['f1']:.6f}\\t{val_metrics['precision']:.6f}\\t{val_metrics['recall']:.6f}\")\n",
    "    print(f\"test\\t{test_metrics['loss']:.6f}\\t{test_metrics['accuracy']:.6f}\\t{test_metrics['f1']:.6f}\\t{test_metrics['precision']:.6f}\\t{test_metrics['recall']:.6f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
